{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from dataloader.dataloader import get_train_val_loaders, get_test_loader\n",
    "from dataloader.transforms import get_train_transforms, get_val_transforms\n",
    "from dataloader.transforms import get_test_transforms\n",
    "\n",
    "train_transforms = get_train_transforms()\n",
    "val_transforms = get_val_transforms()\n",
    "\n",
    "train_dataloader, val_dataloader = get_train_val_loaders(\"./\",\n",
    "                                                        train_transforms,\n",
    "                                                        val_transforms,\n",
    "                                                        128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = [0.5, 0.5, 0.5]\n",
    "mean = [0.5, 0.5, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_dataloader.dataset[104][0]\n",
    "\n",
    "z = x * torch.tensor(std).view(3, 1, 1)\n",
    "z = z + torch.tensor(mean).view(3, 1, 1)\n",
    "\n",
    "img2 = torchvision.transforms.ToPILImage(mode='RGB')(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x134766F28>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    RandomHorizontalFlip(p=0.5)\n",
       "    RandomCrop(size=(32, 32), padding=4)\n",
       "    ToTensor()\n",
       "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x12163c3c8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m1 = build_model(\"cifar_resnet_110\", \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = build_model(\"cifar_freeze_110\", \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m2.parameters())[0].requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv.weight\n",
      "bn.weight\n",
      "bn.bias\n",
      "blocks.0.conv1.weight\n",
      "blocks.0.bn1.weight\n",
      "blocks.0.bn1.bias\n",
      "blocks.0.conv2.weight\n",
      "blocks.0.bn2.weight\n",
      "blocks.0.bn2.bias\n",
      "blocks.1.conv1.weight\n",
      "blocks.1.bn1.weight\n",
      "blocks.1.bn1.bias\n",
      "blocks.1.conv2.weight\n",
      "blocks.1.bn2.weight\n",
      "blocks.1.bn2.bias\n",
      "blocks.2.conv1.weight\n",
      "blocks.2.bn1.weight\n",
      "blocks.2.bn1.bias\n",
      "blocks.2.conv2.weight\n",
      "blocks.2.bn2.weight\n",
      "blocks.2.bn2.bias\n",
      "blocks.3.conv1.weight\n",
      "blocks.3.bn1.weight\n",
      "blocks.3.bn1.bias\n",
      "blocks.3.conv2.weight\n",
      "blocks.3.bn2.weight\n",
      "blocks.3.bn2.bias\n",
      "blocks.4.conv1.weight\n",
      "blocks.4.bn1.weight\n",
      "blocks.4.bn1.bias\n",
      "blocks.4.conv2.weight\n",
      "blocks.4.bn2.weight\n",
      "blocks.4.bn2.bias\n",
      "blocks.5.conv1.weight\n",
      "blocks.5.bn1.weight\n",
      "blocks.5.bn1.bias\n",
      "blocks.5.conv2.weight\n",
      "blocks.5.bn2.weight\n",
      "blocks.5.bn2.bias\n",
      "blocks.6.conv1.weight\n",
      "blocks.6.bn1.weight\n",
      "blocks.6.bn1.bias\n",
      "blocks.6.conv2.weight\n",
      "blocks.6.bn2.weight\n",
      "blocks.6.bn2.bias\n",
      "blocks.7.conv1.weight\n",
      "blocks.7.bn1.weight\n",
      "blocks.7.bn1.bias\n",
      "blocks.7.conv2.weight\n",
      "blocks.7.bn2.weight\n",
      "blocks.7.bn2.bias\n",
      "blocks.8.conv1.weight\n",
      "blocks.8.bn1.weight\n",
      "blocks.8.bn1.bias\n",
      "blocks.8.conv2.weight\n",
      "blocks.8.bn2.weight\n",
      "blocks.8.bn2.bias\n",
      "blocks.9.conv1.weight\n",
      "blocks.9.bn1.weight\n",
      "blocks.9.bn1.bias\n",
      "blocks.9.conv2.weight\n",
      "blocks.9.bn2.weight\n",
      "blocks.9.bn2.bias\n",
      "blocks.10.conv1.weight\n",
      "blocks.10.bn1.weight\n",
      "blocks.10.bn1.bias\n",
      "blocks.10.conv2.weight\n",
      "blocks.10.bn2.weight\n",
      "blocks.10.bn2.bias\n",
      "blocks.11.conv1.weight\n",
      "blocks.11.bn1.weight\n",
      "blocks.11.bn1.bias\n",
      "blocks.11.conv2.weight\n",
      "blocks.11.bn2.weight\n",
      "blocks.11.bn2.bias\n",
      "blocks.12.conv1.weight\n",
      "blocks.12.bn1.weight\n",
      "blocks.12.bn1.bias\n",
      "blocks.12.conv2.weight\n",
      "blocks.12.bn2.weight\n",
      "blocks.12.bn2.bias\n",
      "blocks.13.conv1.weight\n",
      "blocks.13.bn1.weight\n",
      "blocks.13.bn1.bias\n",
      "blocks.13.conv2.weight\n",
      "blocks.13.bn2.weight\n",
      "blocks.13.bn2.bias\n",
      "blocks.14.conv1.weight\n",
      "blocks.14.bn1.weight\n",
      "blocks.14.bn1.bias\n",
      "blocks.14.conv2.weight\n",
      "blocks.14.bn2.weight\n",
      "blocks.14.bn2.bias\n",
      "blocks.15.conv1.weight\n",
      "blocks.15.bn1.weight\n",
      "blocks.15.bn1.bias\n",
      "blocks.15.conv2.weight\n",
      "blocks.15.bn2.weight\n",
      "blocks.15.bn2.bias\n",
      "blocks.16.conv1.weight\n",
      "blocks.16.bn1.weight\n",
      "blocks.16.bn1.bias\n",
      "blocks.16.conv2.weight\n",
      "blocks.16.bn2.weight\n",
      "blocks.16.bn2.bias\n",
      "blocks.17.conv1.weight\n",
      "blocks.17.bn1.weight\n",
      "blocks.17.bn1.bias\n",
      "blocks.17.conv2.weight\n",
      "blocks.17.bn2.weight\n",
      "blocks.17.bn2.bias\n",
      "blocks.18.conv1.weight\n",
      "blocks.18.bn1.weight\n",
      "blocks.18.bn1.bias\n",
      "blocks.18.conv2.weight\n",
      "blocks.18.bn2.weight\n",
      "blocks.18.bn2.bias\n",
      "blocks.18.skip.0.weight\n",
      "blocks.18.skip.1.weight\n",
      "blocks.18.skip.1.bias\n",
      "blocks.19.conv1.weight\n",
      "blocks.19.bn1.weight\n",
      "blocks.19.bn1.bias\n",
      "blocks.19.conv2.weight\n",
      "blocks.19.bn2.weight\n",
      "blocks.19.bn2.bias\n",
      "blocks.20.conv1.weight\n",
      "blocks.20.bn1.weight\n",
      "blocks.20.bn1.bias\n",
      "blocks.20.conv2.weight\n",
      "blocks.20.bn2.weight\n",
      "blocks.20.bn2.bias\n",
      "blocks.21.conv1.weight\n",
      "blocks.21.bn1.weight\n",
      "blocks.21.bn1.bias\n",
      "blocks.21.conv2.weight\n",
      "blocks.21.bn2.weight\n",
      "blocks.21.bn2.bias\n",
      "blocks.22.conv1.weight\n",
      "blocks.22.bn1.weight\n",
      "blocks.22.bn1.bias\n",
      "blocks.22.conv2.weight\n",
      "blocks.22.bn2.weight\n",
      "blocks.22.bn2.bias\n",
      "blocks.23.conv1.weight\n",
      "blocks.23.bn1.weight\n",
      "blocks.23.bn1.bias\n",
      "blocks.23.conv2.weight\n",
      "blocks.23.bn2.weight\n",
      "blocks.23.bn2.bias\n",
      "blocks.24.conv1.weight\n",
      "blocks.24.bn1.weight\n",
      "blocks.24.bn1.bias\n",
      "blocks.24.conv2.weight\n",
      "blocks.24.bn2.weight\n",
      "blocks.24.bn2.bias\n",
      "blocks.25.conv1.weight\n",
      "blocks.25.bn1.weight\n",
      "blocks.25.bn1.bias\n",
      "blocks.25.conv2.weight\n",
      "blocks.25.bn2.weight\n",
      "blocks.25.bn2.bias\n",
      "blocks.26.conv1.weight\n",
      "blocks.26.bn1.weight\n",
      "blocks.26.bn1.bias\n",
      "blocks.26.conv2.weight\n",
      "blocks.26.bn2.weight\n",
      "blocks.26.bn2.bias\n",
      "blocks.27.conv1.weight\n",
      "blocks.27.bn1.weight\n",
      "blocks.27.bn1.bias\n",
      "blocks.27.conv2.weight\n",
      "blocks.27.bn2.weight\n",
      "blocks.27.bn2.bias\n",
      "blocks.28.conv1.weight\n",
      "blocks.28.bn1.weight\n",
      "blocks.28.bn1.bias\n",
      "blocks.28.conv2.weight\n",
      "blocks.28.bn2.weight\n",
      "blocks.28.bn2.bias\n",
      "blocks.29.conv1.weight\n",
      "blocks.29.bn1.weight\n",
      "blocks.29.bn1.bias\n",
      "blocks.29.conv2.weight\n",
      "blocks.29.bn2.weight\n",
      "blocks.29.bn2.bias\n",
      "blocks.30.conv1.weight\n",
      "blocks.30.bn1.weight\n",
      "blocks.30.bn1.bias\n",
      "blocks.30.conv2.weight\n",
      "blocks.30.bn2.weight\n",
      "blocks.30.bn2.bias\n",
      "blocks.31.conv1.weight\n",
      "blocks.31.bn1.weight\n",
      "blocks.31.bn1.bias\n",
      "blocks.31.conv2.weight\n",
      "blocks.31.bn2.weight\n",
      "blocks.31.bn2.bias\n",
      "blocks.32.conv1.weight\n",
      "blocks.32.bn1.weight\n",
      "blocks.32.bn1.bias\n",
      "blocks.32.conv2.weight\n",
      "blocks.32.bn2.weight\n",
      "blocks.32.bn2.bias\n",
      "blocks.33.conv1.weight\n",
      "blocks.33.bn1.weight\n",
      "blocks.33.bn1.bias\n",
      "blocks.33.conv2.weight\n",
      "blocks.33.bn2.weight\n",
      "blocks.33.bn2.bias\n",
      "blocks.34.conv1.weight\n",
      "blocks.34.bn1.weight\n",
      "blocks.34.bn1.bias\n",
      "blocks.34.conv2.weight\n",
      "blocks.34.bn2.weight\n",
      "blocks.34.bn2.bias\n",
      "blocks.35.conv1.weight\n",
      "blocks.35.bn1.weight\n",
      "blocks.35.bn1.bias\n",
      "blocks.35.conv2.weight\n",
      "blocks.35.bn2.weight\n",
      "blocks.35.bn2.bias\n",
      "blocks.36.conv1.weight\n",
      "blocks.36.bn1.weight\n",
      "blocks.36.bn1.bias\n",
      "blocks.36.conv2.weight\n",
      "blocks.36.bn2.weight\n",
      "blocks.36.bn2.bias\n",
      "blocks.36.skip.0.weight\n",
      "blocks.36.skip.1.weight\n",
      "blocks.36.skip.1.bias\n",
      "blocks.37.conv1.weight\n",
      "blocks.37.bn1.weight\n",
      "blocks.37.bn1.bias\n",
      "blocks.37.conv2.weight\n",
      "blocks.37.bn2.weight\n",
      "blocks.37.bn2.bias\n",
      "blocks.38.conv1.weight\n",
      "blocks.38.bn1.weight\n",
      "blocks.38.bn1.bias\n",
      "blocks.38.conv2.weight\n",
      "blocks.38.bn2.weight\n",
      "blocks.38.bn2.bias\n",
      "blocks.39.conv1.weight\n",
      "blocks.39.bn1.weight\n",
      "blocks.39.bn1.bias\n",
      "blocks.39.conv2.weight\n",
      "blocks.39.bn2.weight\n",
      "blocks.39.bn2.bias\n",
      "blocks.40.conv1.weight\n",
      "blocks.40.bn1.weight\n",
      "blocks.40.bn1.bias\n",
      "blocks.40.conv2.weight\n",
      "blocks.40.bn2.weight\n",
      "blocks.40.bn2.bias\n",
      "blocks.41.conv1.weight\n",
      "blocks.41.bn1.weight\n",
      "blocks.41.bn1.bias\n",
      "blocks.41.conv2.weight\n",
      "blocks.41.bn2.weight\n",
      "blocks.41.bn2.bias\n",
      "blocks.42.conv1.weight\n",
      "blocks.42.bn1.weight\n",
      "blocks.42.bn1.bias\n",
      "blocks.42.conv2.weight\n",
      "blocks.42.bn2.weight\n",
      "blocks.42.bn2.bias\n",
      "blocks.43.conv1.weight\n",
      "blocks.43.bn1.weight\n",
      "blocks.43.bn1.bias\n",
      "blocks.43.conv2.weight\n",
      "blocks.43.bn2.weight\n",
      "blocks.43.bn2.bias\n",
      "blocks.44.conv1.weight\n",
      "blocks.44.bn1.weight\n",
      "blocks.44.bn1.bias\n",
      "blocks.44.conv2.weight\n",
      "blocks.44.bn2.weight\n",
      "blocks.44.bn2.bias\n",
      "blocks.45.conv1.weight\n",
      "blocks.45.bn1.weight\n",
      "blocks.45.bn1.bias\n",
      "blocks.45.conv2.weight\n",
      "blocks.45.bn2.weight\n",
      "blocks.45.bn2.bias\n",
      "blocks.46.conv1.weight\n",
      "blocks.46.bn1.weight\n",
      "blocks.46.bn1.bias\n",
      "blocks.46.conv2.weight\n",
      "blocks.46.bn2.weight\n",
      "blocks.46.bn2.bias\n",
      "blocks.47.conv1.weight\n",
      "blocks.47.bn1.weight\n",
      "blocks.47.bn1.bias\n",
      "blocks.47.conv2.weight\n",
      "blocks.47.bn2.weight\n",
      "blocks.47.bn2.bias\n",
      "blocks.48.conv1.weight\n",
      "blocks.48.bn1.weight\n",
      "blocks.48.bn1.bias\n",
      "blocks.48.conv2.weight\n",
      "blocks.48.bn2.weight\n",
      "blocks.48.bn2.bias\n",
      "blocks.49.conv1.weight\n",
      "blocks.49.bn1.weight\n",
      "blocks.49.bn1.bias\n",
      "blocks.49.conv2.weight\n",
      "blocks.49.bn2.weight\n",
      "blocks.49.bn2.bias\n",
      "blocks.50.conv1.weight\n",
      "blocks.50.bn1.weight\n",
      "blocks.50.bn1.bias\n",
      "blocks.50.conv2.weight\n",
      "blocks.50.bn2.weight\n",
      "blocks.50.bn2.bias\n",
      "blocks.51.conv1.weight\n",
      "blocks.51.bn1.weight\n",
      "blocks.51.bn1.bias\n",
      "blocks.51.conv2.weight\n",
      "blocks.51.bn2.weight\n",
      "blocks.51.bn2.bias\n",
      "blocks.52.conv1.weight\n",
      "blocks.52.bn1.weight\n",
      "blocks.52.bn1.bias\n",
      "blocks.52.conv2.weight\n",
      "blocks.52.bn2.weight\n",
      "blocks.52.bn2.bias\n",
      "blocks.53.conv1.weight\n",
      "blocks.53.bn1.weight\n",
      "blocks.53.bn1.bias\n",
      "blocks.53.conv2.weight\n",
      "blocks.53.bn2.weight\n",
      "blocks.53.bn2.bias\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "source": [
    "for name, params in m1.named_parameters():\n",
    "    print (name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import print_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_nets = [\"cifar_resnet_14\", \n",
    "             \"cifar_resnet_32\", \n",
    "             \"cifar_resnet_56\", \n",
    "             \"cifar_resnet_110\",\n",
    "             \"cifar_resnet_218\",\n",
    "             \"cifar_resnet_434\", \n",
    "             \"cifar_resnet_866\",]\n",
    "wide_nets = [\"cifar_resnet_14_1\", \n",
    "             \"cifar_resnet_14_2\", \n",
    "             \"cifar_resnet_14_4\", \n",
    "             \"cifar_resnet_14_8\",\n",
    "             \"cifar_resnet_14_16\",\n",
    "             \"cifar_resnet_14_32\",]\n",
    "\n",
    "deep_freeze_nets = list(map(lambda x: x.replace(\"resnet\", \"freeze\"), deep_nets))\n",
    "wide_freeze_nets = list(map(lambda x: x.replace(\"resnet\", \"freeze\"), wide_nets))\n",
    "\n",
    "models = [*deep_nets, *wide_nets]\n",
    "freeze_models = [*deep_freeze_nets, *wide_freeze_nets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           BatchNorm          Shortcut            Output             Total         Trainable\n",
      "   cifar_resnet_14              1120              2752               650            175258            175258\n",
      "   cifar_resnet_32              2464              2752               650            466906            466906\n",
      "   cifar_resnet_56              4256              2752               650            855770            855770\n",
      "  cifar_resnet_110              8288              2752               650           1730714           1730714\n",
      "  cifar_resnet_218             16352              2752               650           3480602           3480602\n",
      "  cifar_resnet_434             32480              2752               650           6980378           6980378\n",
      "  cifar_resnet_866             64736              2752               650          13979930          13979930\n",
      " cifar_resnet_14_1              1120              2752               650            175258            175258\n",
      " cifar_resnet_14_2              2240             10624              1290            696618            696618\n",
      " cifar_resnet_14_4              4480             41728              2570           2777674           2777674\n",
      " cifar_resnet_14_8              8960            165376              5130          11093130          11093130\n",
      "cifar_resnet_14_16             17920            658432             10250          44337418          44337418\n",
      "cifar_resnet_14_32             35840           2627584             20490         177279498         177279498\n",
      "   cifar_freeze_14              1120              2752               650            175258               560\n",
      "   cifar_freeze_32              2464              2752               650            466906              1232\n",
      "   cifar_freeze_56              4256              2752               650            855770              2128\n",
      "  cifar_freeze_110              8288              2752               650           1730714              4144\n",
      "  cifar_freeze_218             16352              2752               650           3480602              8176\n",
      "  cifar_freeze_434             32480              2752               650           6980378             16240\n",
      "  cifar_freeze_866             64736              2752               650          13979930             32368\n",
      " cifar_freeze_14_1              1120              2752               650            175258               560\n",
      " cifar_freeze_14_2              2240             10624              1290            696618              1120\n",
      " cifar_freeze_14_4              4480             41728              2570           2777674              2240\n",
      " cifar_freeze_14_8              8960            165376              5130          11093130              4480\n",
      "cifar_freeze_14_16             17920            658432             10250          44337418              8960\n",
      "cifar_freeze_14_32             35840           2627584             20490         177279498             17920\n"
     ]
    }
   ],
   "source": [
    "print_table([*models, *freeze_models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lr(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine.train import train_one_epoch, validate\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from argparse import ArgumentParser\n",
    "# from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# from dataloader.dataloader import get_train_val_loader, get_test_loader\n",
    "# from dataloader.transforms import get_train_transforms, get_val_transforms\n",
    "# from dataloader.transforms import get_test_transforms\n",
    "from utils.utils import accuracy\n",
    "from models.builder import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = build_model(\"ResNet18\", device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "metric = accuracy\n",
    "# Make config for easy use with functions\n",
    "config = {\"model\" : model,\n",
    "          \"optimizer\" : optimizer,\n",
    "          \"lr_scheduler\" : lr_scheduler,\n",
    "          \"loss_fn\" : loss_fn,\n",
    "          \"metric\" : metric,\n",
    "          \"device\" : device}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\"ResNet18\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_transforms = get_test_transforms()\n",
    "test_dataloader = get_test_loader(\"\",\n",
    "                                  test_transforms,\n",
    "                                  128)\n",
    "# Add dataloader in config\n",
    "config.update({\"test_dataloader\" : test_dataloader})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.update({\"train_dataloader\" : train_dataloader})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "im = Image.fromarray(np.uint8(train_dataloader.dataset.data[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    RandomVerticalFlip(p=0.5)\n",
       "    RandomCrop(size=(32, 32), padding=4)\n",
       "    ToTensor()\n",
       "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       ")"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torchvision.transforms.RandomCrop(32, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "q = torchvision.transforms.RandomHorizontalFlip(p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAI0klEQVR4nAXB6Y5cx3kA0Kr6ar9r93T39JBDyhLlGPKPwL8cxK9gIG9sGH4AA0HiWJZIi6JocoYzvd6l6taec/D9nVZKYYwpAUJIzAlhfLkOkvCK0NFZooUSvKqqruvP55OfXUEo+IAwAgqcka6Sd9vVpy9fZp/adhVDmefr/cuWMUoppQwgxZBTxpy7GIECwrhvdFtVfpyz9ZqpTiutZM3ZwbpcnJRiu92cz2ep5Iu7HaCy262Zku8/fuYM931VV+im6zDCs5kppwRjstrczNawBDFGXMrdfrff3rx/988N7fYv9iQSgnGr5E3XFFBd1+lKA4nb243kbByusYSu717GAhRRVgSI7FPbtCVk/Pt/v5dK7na7p+NRCnE9X243WyGg7fT1cqmqKvjIERdcGGsJwYVlLrj33jnHOKQUheAIofG6OJduNo2qwJmFep5zXpaFbjY3OWe/LLf7nZZKANxttyGY4+GpaRvKSPaZUUxIsWZAGBEJzlvnnRBiGsaq1iml4+ksWIUx8t6N00QQ9kPyPtRVRQnK3i3Ju0iyWwwFMlxOGKWS0qeHh65uNOWDu5ZSuKQhhuAdJiTHlCEJzlBBxjouNGdCSywEv14u18u1lh0G0G1HMSqc01JKTMEtdqUqRjAlbPHAhfTO+2HmteKcYwYpOiVV8KFpeyklxmmcpuATZkJKiUJwxiVPOK3b9TqEOMyGEkJKLqpSC868qtLsEKb729t4LCj6igs3Tt1+bYxBCG1ut27ygBljQgq12ElwRXh9nV0ICVJcloAyKCkp50vwz4dn+un5WkqpXK67avGpBvnybiU0hjNaad5r2ew3jpQfHz/3fevm82IiAxmGuDiXMQCDaRqjRT6Vba/X7ert+NPNaoUBtZXKoaEu5tPppM2yDp4hKutqMcNkIsIIYnSj2zb1D2/f11LXSjlnV3drnFg0TlI0LkkI+fjlM8qq7vrFmhiCktBU/DROi1uauia7ddNqvqpFiR5QVoqXgozxfokE0+9+89t5ts6VttvGBBkxXVfAqFASBJvN9PTlsWtbzmnKARgLKb18/Ypwfh6m2XqpG1oL+O7Na6U1Afr48SFGV9W7y7QA5hjh8To+Px1CQAixaZpyCcbM07C0uvEoFByBkLZplKaUQtNIIJBzfv/LR0w5BxjNQmsOla4YZ12/Vhidj8f/+/7HmIng9bpaff706Xg4LFEO1xFhUjK6XM7BI++81rC+6TAmLqaSi11sQS7G6JxLOSldIYQo4/R+v0s5rfoVYGCb1X5786c//yVn6Bv8+LDcrmTf1Zcne3h67FdtVfFu1TbVuum6qmbR2p/efQDKjfPee+8SAMEoKykSZiGE4BZaShacAZAwzwJwYThlQggjCKEcvvrq6812e/8wCcHargLAT0+f/vAfv9+/eBHLMhyfz4fz8TJTKNtNl3PJKXV1fb6OhWBvlxQi/eXjv+qqGse5F9yjkCjTTeNt3G1Xgtg337wUghOmuGBKMUJwsaMbptDZm7uORPvVq3shh2G+cE4ppjEEoJCcB1mV6OpqTY11GWEf03q7zjkuS3j16tXf//YDo/huv91uV4AzY4gLqrUEwMju7TCcnp8KWZTEWsu2KYM5lRSUVJjyEHyrdKK41ZwBogSYW7yg3HknJCEhJ2/H88VMw9ev3yiBa910KxViSMkDkM2meXqyD8+nv/7tf7799vXT8/D54Tki17cNQ1kIGSm4ZckY6XU/TBPdb/aCES240jgmz3JpZXzz8rbX6sWurwW0lVyI4pkP1ygrxTR7fJ4+nswP7748Pi3DdQph+u13d7VkyTiUoZQiOUsxYaAxRVoIkUozSpggy+hCSF3T/u53G8UKY5xSnnJGZBGc1jXjApdMGSF//8cPswkozc4FDowQUTDOJA3WjmahwL2P0S3eOepDHGdDGm0vY4hBqwYIvxyvjpXrZENaFRcZxYyASQ4l5K3Tgj4+PrgiHQROOUgwJkXvBefXxT4ezwUBKhjjpASlh/Plxe5mnE3My/pmPQ4mRuO8zwX94917gjMH8vpXL0gtljkl76O3AsjlfP3x04evt3frpqPrdp7DOV4pp6NdznbJhWBEGY6zcfTj58+MQfT21av9bNwwmRgLEDDRf//uJ0rg88eHzXrVdf3bt+8KKv/1x/8UpV31jRrC8XLJPjMGw6RnNxtvCRdLyBhozvk8XTeNorGU4/XaajlMBijNCGZrCEEl20bB08n89/9+qNSzWwJCmUv4/u2HW71pKrbfb44fHjHFT8/P9/c3KWMXi5nHmHHKtmlrn8vsM13dbNq2koyehlEpHXzyMVFGuOA+hafTuESybvr7bzYhxGG8/PyvZ75lpMRac7xbtaqdLsPPH35+82+vfcE+LSgjM4+v162S3FlPRmNOlwsihCttnOeqErqiUjIpMRNmSVzJ+qYOJEYaZa8zVeNkfv3NV9u+ERKu0+mbb782iwkxYUSnwZhpqZWuNU8lg26ornSK3oVAGTDGAQAhQhiiLCOEXA6Ygu74OI5KqefnE6XNShHdt7W0t9vuUM5as93uZhwGnxDBqO36plXD9XI4HAqpqVScYG69ExmU4BhFzgABbrv1Mlw99VRk6xcAHhzytjwsh/XLl+HhSeEiG9h2u8Pxl3XXIsKm6H5z9yIXMCaYOay7PkREORCtdUoJUALAKYUYfQEyjmCHAVCSkvoQg43m6jhVzbpHXARjgRcueGG0aZWg0K+3ZThhkpZxtiZJrTHGqBRacUERJghJKadpAgAuhKo0F0IRZK+X293rBaW+kmzLS0YBuZiiqiumOcIoYLzZ1jxToEwIWYrTulaaIwBrrbWWsFIgRQWUIEwIyTlzxmKMi50JRl1TE4yk0KUUXWnOaUrJxYSAMi58SEJojMA6vywBCHAuORcplePxPAwTxkAVZymlkhMAa9s254wxvlzOJcdOqZrTksG6hHPJ4dBUdSkoITR7xwKz1kViD9dxOg59vznOZ6lIKfR8MqMxSiml1P8DO8ZmN72lJ8MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x13F98B550>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x12B2AEF28>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 59,  62,  63],\n",
       "        [ 43,  46,  45],\n",
       "        [ 50,  48,  43],\n",
       "        ...,\n",
       "        [158, 132, 108],\n",
       "        [152, 125, 102],\n",
       "        [148, 124, 103]],\n",
       "\n",
       "       [[ 16,  20,  20],\n",
       "        [  0,   0,   0],\n",
       "        [ 18,   8,   0],\n",
       "        ...,\n",
       "        [123,  88,  55],\n",
       "        [119,  83,  50],\n",
       "        [122,  87,  57]],\n",
       "\n",
       "       [[ 25,  24,  21],\n",
       "        [ 16,   7,   0],\n",
       "        [ 49,  27,   8],\n",
       "        ...,\n",
       "        [118,  84,  50],\n",
       "        [120,  84,  50],\n",
       "        [109,  73,  42]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[208, 170,  96],\n",
       "        [201, 153,  34],\n",
       "        [198, 161,  26],\n",
       "        ...,\n",
       "        [160, 133,  70],\n",
       "        [ 56,  31,   7],\n",
       "        [ 53,  34,  20]],\n",
       "\n",
       "       [[180, 139,  96],\n",
       "        [173, 123,  42],\n",
       "        [186, 144,  30],\n",
       "        ...,\n",
       "        [184, 148,  94],\n",
       "        [ 97,  62,  34],\n",
       "        [ 83,  53,  34]],\n",
       "\n",
       "       [[177, 144, 116],\n",
       "        [168, 129,  94],\n",
       "        [179, 142,  87],\n",
       "        ...,\n",
       "        [216, 184, 140],\n",
       "        [151, 118,  84],\n",
       "        [123,  92,  72]]], dtype=uint8)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset.data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from utils import is_valid_cifar_name, get_plan\n",
    "from resnet_cifar import ResNetCifar\n",
    "from utils import is_valid_cifar_name, get_plan, weight_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'cifar_freeze_110'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"cifar_resnet_14\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    }
   ],
   "source": [
    "from test import predict\n",
    "\n",
    "test_predictions, metric_values = predict(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "max() received an invalid combination of arguments - got (list, int), but expected one of:\n * (Tensor input)\n * (Tensor input, name dim, bool keepdim, tuple of Tensors out)\n * (Tensor input, Tensor other, Tensor out)\n * (Tensor input, int dim, bool keepdim, tuple of Tensors out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-687b712de4b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: max() received an invalid combination of arguments - got (list, int), but expected one of:\n * (Tensor input)\n * (Tensor input, name dim, bool keepdim, tuple of Tensors out)\n * (Tensor input, Tensor other, Tensor out)\n * (Tensor input, int dim, bool keepdim, tuple of Tensors out)\n"
     ]
    }
   ],
   "source": [
    "_, pred_labels = torch.max(predicitons.data, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4734)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions[0].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1, 2, 3, 4'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\", \".join(map(str, c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = [1, 2, 3, 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparation in progress ...\n",
      "Testing mode\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric value on test = 16.62381329113924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "%run runner.py --batch-size 128  --model cifar_resnet_14 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: Module created for script run in IPython [-h] [--name NAME]\n",
      "                                                [--model MODEL] [--train]\n",
      "                                                [--epoch EPOCH]\n",
      "                                                [--batch-size BATCH_SIZE]\n",
      "                                                [--learning-rate LEARNING_RATE]\n",
      "                                                [--weight-path WEIGHT_PATH]\n",
      "                                                [--gpu] [--data-dir DATA_DIR]\n",
      "Module created for script run in IPython: error: unrecognized arguments: --test\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "%run runner.py --batch-size 128 \\\n",
    "                      --model cifar_resnet_14 \\\n",
    "                      --test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparation in progress ...\n",
      "Training mode\n",
      "Reading transforms\n",
      "Reading data\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Start training\n",
      "Starting 1/2 epoch\n",
      "Epoch 1/2:                                                                      \n",
      "TRAIN loss = 1.56   |   accuracy = 41.97%\n",
      "VALID loss = 1.27   |   accuracy = 52.21%\n",
      "Starting 2/2 epoch\n",
      " 91%|█████████████████████████████████████▏   | 319/352 [03:15<00:19,  1.68it/s]"
     ]
    }
   ],
   "source": [
    "!python runner.py --train --epoch 2 --batch-size 128 --learning-rate 0.1 --model cifar_resnet_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparation in progress ...\n",
      "Testing mode\n",
      "Files already downloaded and verified\n",
      "Metric value on test = 10.027689873417721                                       \n"
     ]
    }
   ],
   "source": [
    "!python runner.py  --batch-size 128 --learning-rate 0.1 --model cifar_freeze_14_2 --weight-path \"init\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if name.startswith('cifar_resnet_'):\n",
    "    if not is_valid_cifar_name(name):\n",
    "        raise ValueError(f'Invalid model name: {name}')\n",
    "\n",
    "# initializer = nn.init.xavier_uniform\n",
    "# plan = get_plan(name)\n",
    "model = build_model(name, \"cpu\")\n",
    "# model.to(device)\n",
    "# return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"cifar_resnet_14\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = build_model(name, \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             432\n",
      "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
      "            Conv2d-3           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-4           [-1, 16, 32, 32]              32\n",
      "            Conv2d-5           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-6           [-1, 16, 32, 32]              32\n",
      "       ResNetBlock-7           [-1, 16, 32, 32]               0\n",
      "            Conv2d-8           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-9           [-1, 16, 32, 32]              32\n",
      "           Conv2d-10           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-11           [-1, 16, 32, 32]              32\n",
      "      ResNetBlock-12           [-1, 16, 32, 32]               0\n",
      "           Conv2d-13           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-14           [-1, 32, 16, 16]              64\n",
      "           Conv2d-15           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-16           [-1, 32, 16, 16]              64\n",
      "           Conv2d-17           [-1, 32, 16, 16]             512\n",
      "      BatchNorm2d-18           [-1, 32, 16, 16]              64\n",
      "      ResNetBlock-19           [-1, 32, 16, 16]               0\n",
      "           Conv2d-20           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-21           [-1, 32, 16, 16]              64\n",
      "           Conv2d-22           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-23           [-1, 32, 16, 16]              64\n",
      "      ResNetBlock-24           [-1, 32, 16, 16]               0\n",
      "           Conv2d-25             [-1, 64, 8, 8]          18,432\n",
      "      BatchNorm2d-26             [-1, 64, 8, 8]             128\n",
      "           Conv2d-27             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
      "           Conv2d-29             [-1, 64, 8, 8]           2,048\n",
      "      BatchNorm2d-30             [-1, 64, 8, 8]             128\n",
      "      ResNetBlock-31             [-1, 64, 8, 8]               0\n",
      "           Conv2d-32             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-33             [-1, 64, 8, 8]             128\n",
      "           Conv2d-34             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-35             [-1, 64, 8, 8]             128\n",
      "      ResNetBlock-36             [-1, 64, 8, 8]               0\n",
      "           Linear-37                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 175,258\n",
      "Trainable params: 175,258\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.63\n",
      "Params size (MB): 0.67\n",
      "Estimated Total Size (MB): 3.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetCifar(\n",
      "  (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (blocks): Sequential(\n",
      "    (0): ResNetBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip): Sequential()\n",
      "    )\n",
      "    (1): ResNetBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip): Sequential()\n",
      "    )\n",
      "    (2): ResNetBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): ResNetBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip): Sequential()\n",
      "    )\n",
      "    (4): ResNetBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): ResNetBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2988"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
