{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from dataloader import get_train_val_loader, get_test_loader\n",
    "from transforms import get_train_transforms, get_val_transforms\n",
    "from transforms import get_test_transforms\n",
    "\n",
    "train_transforms = get_train_transforms()\n",
    "val_transforms = get_val_transforms()\n",
    "\n",
    "train_dataloader, val_dataloader = get_train_val_loader(\"./\",\n",
    "                                                        train_transforms,\n",
    "                                                        val_transforms,\n",
    "                                                        128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lr(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train_one_epoch, validate\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from argparse import ArgumentParser\n",
    "# from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from dataloader import get_train_val_loader, get_test_loader\n",
    "from transforms import get_train_transforms, get_val_transforms\n",
    "from transforms import get_test_transforms\n",
    "from utils import accuracy\n",
    "from model import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = build_model(\"ResNet18\", device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "metric = accuracy\n",
    "# Make config for easy use with functions\n",
    "config = {\"model\" : model,\n",
    "          \"optimizer\" : optimizer,\n",
    "          \"lr_scheduler\" : lr_scheduler,\n",
    "          \"loss_fn\" : loss_fn,\n",
    "          \"metric\" : metric,\n",
    "          \"device\" : device}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_transforms = get_test_transforms()\n",
    "test_dataloader = get_test_loader(\"\",\n",
    "                                  test_transforms,\n",
    "                                  128)\n",
    "# Add dataloader in config\n",
    "config.update({\"test_dataloader\" : test_dataloader})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.update({\"train_dataloader\" : train_dataloader})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "im = Image.fromarray(np.uint8(train_dataloader.dataset.data[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    RandomVerticalFlip(p=0.5)\n",
       "    RandomCrop(size=(32, 32), padding=4)\n",
       "    ToTensor()\n",
       "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       ")"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torchvision.transforms.RandomCrop(32, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "q = torchvision.transforms.RandomHorizontalFlip(p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x13F98B550>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x12B2AEF28>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 59,  62,  63],\n",
       "        [ 43,  46,  45],\n",
       "        [ 50,  48,  43],\n",
       "        ...,\n",
       "        [158, 132, 108],\n",
       "        [152, 125, 102],\n",
       "        [148, 124, 103]],\n",
       "\n",
       "       [[ 16,  20,  20],\n",
       "        [  0,   0,   0],\n",
       "        [ 18,   8,   0],\n",
       "        ...,\n",
       "        [123,  88,  55],\n",
       "        [119,  83,  50],\n",
       "        [122,  87,  57]],\n",
       "\n",
       "       [[ 25,  24,  21],\n",
       "        [ 16,   7,   0],\n",
       "        [ 49,  27,   8],\n",
       "        ...,\n",
       "        [118,  84,  50],\n",
       "        [120,  84,  50],\n",
       "        [109,  73,  42]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[208, 170,  96],\n",
       "        [201, 153,  34],\n",
       "        [198, 161,  26],\n",
       "        ...,\n",
       "        [160, 133,  70],\n",
       "        [ 56,  31,   7],\n",
       "        [ 53,  34,  20]],\n",
       "\n",
       "       [[180, 139,  96],\n",
       "        [173, 123,  42],\n",
       "        [186, 144,  30],\n",
       "        ...,\n",
       "        [184, 148,  94],\n",
       "        [ 97,  62,  34],\n",
       "        [ 83,  53,  34]],\n",
       "\n",
       "       [[177, 144, 116],\n",
       "        [168, 129,  94],\n",
       "        [179, 142,  87],\n",
       "        ...,\n",
       "        [216, 184, 140],\n",
       "        [151, 118,  84],\n",
       "        [123,  92,  72]]], dtype=uint8)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset.data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from utils import is_valid_cifar_name, get_plan\n",
    "from resnet_cifar import ResNetCifar\n",
    "from utils import is_valid_cifar_name, get_plan, weight_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'cifar_freeze_110'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"cifar_resnet_14\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    }
   ],
   "source": [
    "from test import predict\n",
    "\n",
    "test_predictions, metric_values = predict(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "max() received an invalid combination of arguments - got (list, int), but expected one of:\n * (Tensor input)\n * (Tensor input, name dim, bool keepdim, tuple of Tensors out)\n * (Tensor input, Tensor other, Tensor out)\n * (Tensor input, int dim, bool keepdim, tuple of Tensors out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-687b712de4b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: max() received an invalid combination of arguments - got (list, int), but expected one of:\n * (Tensor input)\n * (Tensor input, name dim, bool keepdim, tuple of Tensors out)\n * (Tensor input, Tensor other, Tensor out)\n * (Tensor input, int dim, bool keepdim, tuple of Tensors out)\n"
     ]
    }
   ],
   "source": [
    "_, pred_labels = torch.max(predicitons.data, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4734)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions[0].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1, 2, 3, 4'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\", \".join(map(str, c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = [1, 2, 3, 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparation in progress ...\n",
      "Testing mode\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric value on test = 16.62381329113924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "%run runner.py --batch-size 128  --model cifar_resnet_14 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: Module created for script run in IPython [-h] [--name NAME]\n",
      "                                                [--model MODEL] [--train]\n",
      "                                                [--epoch EPOCH]\n",
      "                                                [--batch-size BATCH_SIZE]\n",
      "                                                [--learning-rate LEARNING_RATE]\n",
      "                                                [--weight-path WEIGHT_PATH]\n",
      "                                                [--gpu] [--data-dir DATA_DIR]\n",
      "Module created for script run in IPython: error: unrecognized arguments: --test\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "%run runner.py --batch-size 128 \\\n",
    "                      --model cifar_resnet_14 \\\n",
    "                      --test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparation in progress ...\n",
      "Training mode\n",
      "Reading transforms\n",
      "Reading data\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Start training\n",
      "Starting 1/2 epoch\n",
      "Epoch 2/2:                                                                      \n",
      "TRAIN loss = 2.03   |   accuracy = 23.03\n",
      "VALID loss = 2.51   |   accuracy = 22.17%\n",
      "Starting 2/2 epoch\n",
      "Epoch 3/2:                                                                      \n",
      "TRAIN loss = 1.81   |   accuracy = 30.78\n",
      "VALID loss = 1.94   |   accuracy = 27.43%\n",
      "Training is over! \n",
      "Best validation loss = 1.9388532848520712 \n",
      "Accuracy for best loss = 27.42833609532828\n"
     ]
    }
   ],
   "source": [
    "!python runner.py --train --epoch 2 --batch-size 128 --learning-rate 0.1 --model cifar_resnet_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparation in progress ...\n",
      "Testing mode\n",
      "Files already downloaded and verified\n",
      "Metric value on test = 42.50395569620253                                        \n"
     ]
    }
   ],
   "source": [
    "!python runner.py  --batch-size 128 --learning-rate 0.1 --model cifar_resnet_14 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if name.startswith('cifar_resnet_'):\n",
    "    if not is_valid_cifar_name(name):\n",
    "        raise ValueError(f'Invalid model name: {name}')\n",
    "\n",
    "# initializer = nn.init.xavier_uniform\n",
    "# plan = get_plan(name)\n",
    "model = build_model(name, \"cpu\")\n",
    "# model.to(device)\n",
    "# return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"cifar_resnet_14\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = build_model(name, \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             432\n",
      "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
      "            Conv2d-3           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-4           [-1, 16, 32, 32]              32\n",
      "            Conv2d-5           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-6           [-1, 16, 32, 32]              32\n",
      "       ResNetBlock-7           [-1, 16, 32, 32]               0\n",
      "            Conv2d-8           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-9           [-1, 16, 32, 32]              32\n",
      "           Conv2d-10           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-11           [-1, 16, 32, 32]              32\n",
      "      ResNetBlock-12           [-1, 16, 32, 32]               0\n",
      "           Conv2d-13           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-14           [-1, 32, 16, 16]              64\n",
      "           Conv2d-15           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-16           [-1, 32, 16, 16]              64\n",
      "           Conv2d-17           [-1, 32, 16, 16]             512\n",
      "      BatchNorm2d-18           [-1, 32, 16, 16]              64\n",
      "      ResNetBlock-19           [-1, 32, 16, 16]               0\n",
      "           Conv2d-20           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-21           [-1, 32, 16, 16]              64\n",
      "           Conv2d-22           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-23           [-1, 32, 16, 16]              64\n",
      "      ResNetBlock-24           [-1, 32, 16, 16]               0\n",
      "           Conv2d-25             [-1, 64, 8, 8]          18,432\n",
      "      BatchNorm2d-26             [-1, 64, 8, 8]             128\n",
      "           Conv2d-27             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
      "           Conv2d-29             [-1, 64, 8, 8]           2,048\n",
      "      BatchNorm2d-30             [-1, 64, 8, 8]             128\n",
      "      ResNetBlock-31             [-1, 64, 8, 8]               0\n",
      "           Conv2d-32             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-33             [-1, 64, 8, 8]             128\n",
      "           Conv2d-34             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-35             [-1, 64, 8, 8]             128\n",
      "      ResNetBlock-36             [-1, 64, 8, 8]               0\n",
      "           Linear-37                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 175,258\n",
      "Trainable params: 175,258\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.63\n",
      "Params size (MB): 0.67\n",
      "Estimated Total Size (MB): 3.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetCifar(\n",
      "  (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (blocks): Sequential(\n",
      "    (0): ResNetBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip): Sequential()\n",
      "    )\n",
      "    (1): ResNetBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip): Sequential()\n",
      "    )\n",
      "    (2): ResNetBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): ResNetBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip): Sequential()\n",
      "    )\n",
      "    (4): ResNetBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): ResNetBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2988"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
